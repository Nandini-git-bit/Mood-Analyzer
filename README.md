# üé≠ Mood Analyzer

This project analyzes the mood or emotion of a given text using NLP and Machine Learning.

## üß† Features
üß© Mood Detection: Analyzes user text and predicts the mood (Happy, Sad, Angry, Neutral).

üí¨ Mood-based Quotes: Displays motivational or mood-related quotes according to the detected emotion.

üéÆ Mini Games: Includes simple interactive games to cheer up the user or improve their mood.

üòÇ Funny Jokes Section: Suggests jokes or fun messages when the user feels sad or stressed.

üßò User Engagement: Helps users relax, smile, and improve their emotional state with fun interactions.

‚öôÔ∏è Tech Stack: Built using Python, Scikit-learn, and NLP techniques for text-based emotion analysis.

## ‚öôÔ∏è How to Run
1. Clone this repo:
   ```bash
   git clone https://github.com/Nandini-git-bit/Mood-Analyzer.git


 You can find the measured scores of various models in DeepFace and the reported scores from their original studies in the following table.

| Model          | Measured Score | Declared Score     |
| -------------- | -------------- | ------------------ |
| Facenet512     | 98.4%          | 99.6%              |
| Human-beings   | 97.5%          | 97.5%              |
| Facenet        | 97.4%          | 99.2%              |
| Dlib           | 96.8%          | 99.3 %             |
| VGG-Face       | 96.7%          | 98.9%              |
| ArcFace        | 96.7%          | 99.5%              |
| GhostFaceNet   | 93.3%          | 99.7%              |
| SFace          | 93.0%          | 99.5%              |
| OpenFace       | 78.7%          | 92.9%              |
| DeepFace       | 69.0%          | 97.3%              |
| DeepID         | 66.5%          | 97.4%              |

Conducting experiments with those models within DeepFace may reveal disparities compared to the original studies, owing to the adoption of distinct detection or normalization techniques. Furthermore, some models have been released solely with their backbones, lacking pre-trained weights. Thus, we are utilizing their re-implementations instead of the original pre-trained weights.




